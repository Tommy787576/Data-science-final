{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","provenance":[],"mount_file_id":"1tX-PRk_NYzAi3Gdh5cg72np98Rl2jo2Y","authorship_tag":"ABX9TyNm6vRYMVVTNgDv80dpW+t9"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"TgEBoKLVHZom"},"source":["#build function"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x0uEFdtAIK6V"},"source":["#install tensorboard if you want to record training log\n","!pip install tensorboardX"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BiAJbGA51dta"},"source":["#for google colab, ignore this\n","%cd /content/drive/MyDrive/DataScience"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wonmx2h54cA5","executionInfo":{"status":"ok","timestamp":1607111452962,"user_tz":-480,"elapsed":6042,"user":{"displayName":"葉彥廷","photoUrl":"","userId":"03165483084691048586"}}},"source":["#require: pytorch\n","import os\n","import numpy as np\n","import time\n","import datetime\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import pandas as pd\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"C6DJP7AbCQ7q","executionInfo":{"status":"ok","timestamp":1607111458133,"user_tz":-480,"elapsed":1039,"user":{"displayName":"葉彥廷","photoUrl":"","userId":"03165483084691048586"}}},"source":["def infinite_iter(iterable):\n","  it = iter(iterable)\n","  while True:\n","    try:\n","      ret = next(it)\n","      yield ret\n","    except StopIteration:\n","      it = iter(iterable)\n","\n","class myDataset(Dataset):\n","  def __init__(self, csv_file):\n","    self.df_train = pd.read_csv(csv_file)\n","    self.x_size = 358 #19 column, some are onehot encoded\n","\n","  def __len__(self):\n","    return len(self.df_train)\n","  \n","  def dfrow2tensor(self, row):\n","    ten = np.zeros(0)\n","    onehot_column = {'ind_empleado': 5, 'pais_residencia': 118, 'indrel_1mes': 4,\n","            'tiprel_1mes': 4, 'canal_entrada': 162, 'cod_prov': 52}\n","    for col in self.df_train.columns:\n","      if col == 'ncodpers':\n","        continue\n","      if col in onehot_column:\n","        _ = np.zeros(onehot_column[col])\n","        _[int(row[col])] = 1\n","        ten = np.concatenate((ten, _), axis=None)\n","      else:\n","        _ = np.array([float(row[col])])\n","        ten = np.concatenate((ten, _), axis=None)\n","    return ten\n","\n","  def __getitem__(self, idx):\n","    r = self.df_train.iloc[idx]\n","    ten = self.dfrow2tensor(r)\n","    x = ten[:self.x_size]\n","    y = ten[self.x_size:]\n","    x = torch.from_numpy(x)\n","    y = torch.from_numpy(y)\n","    return (x, y)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"RpdVRs1CBIUY","executionInfo":{"status":"ok","timestamp":1607111460855,"user_tz":-480,"elapsed":988,"user":{"displayName":"葉彥廷","photoUrl":"","userId":"03165483084691048586"}}},"source":["class LogisticRegression(nn.Module):\n","  def __init__(self):\n","    super(LogisticRegression, self).__init__()\n","    self.linear = torch.nn.Linear(358, 24) #\n","    self.act = torch.nn.Sigmoid()\n","  def forward(self, x):\n","    y = self.linear(x)\n","    y = self.act(y)\n","    return y\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"hzllkVV94Stc","executionInfo":{"status":"ok","timestamp":1607111464100,"user_tz":-480,"elapsed":1026,"user":{"displayName":"葉彥廷","photoUrl":"","userId":"03165483084691048586"}}},"source":["def get_loss(y, label):\n","  criterion = nn.L1Loss()\n","  loss = criterion(y, label)\n","  return loss\n","\n","def save_model(dir, model, opt, iter):\n","  if not os.path.exists(dir):\n","    os.mkdir(dir)\n","  if iter < 0:\n","    torch.save(model.state_dict(), f'{dir}/model.ckpt')\n","    torch.save(opt.state_dict(), f'{dir}/opt.opt')\n","  else:\n","    torch.save(model.state_dict(), f'{dir}/model.ckpt-{iter}')\n","    torch.save(opt.state_dict(), f'{dir}/opt.opt-{iter}')\n","\n","def load_model(dir, model, opt, iter):\n","  if iter < 0:\n","    model.load_state_dict(torch.load(f'{dir}/model.ckpt'))\n","    opt.load_state_dict(torch.load(f'{dir}/opt.opt'))\n","  else:\n","    model.load_state_dict(torch.load(f'{dir}/model.ckpt-{iter}'))\n","    opt.load_state_dict(torch.load(f'{dir}/opt.opt-{iter}'))\n","  return model, opt\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"RIS7ai5dHkkB"},"source":["#load train data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XyhqBgj-r28J"},"source":["print(\"loading data...\")\n","s_t = time.time()\n","train_dataset = myDataset('./data/processed/train.csv')\n","train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n","train_iterator = infinite_iter(train_loader)\n","\n","#test_dataset = myDataset('./data/processed/test.csv')\n","#test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=2)\n","#test_iterator = infinite_iter(test_loader)\n","\n","print(\"data prepared!\")\n","et = time.time() - s_t\n","et = str(datetime.timedelta(seconds=et))[:-7]\n","print(\"[{}]\".format(et))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ymZZ1hqSHpQa"},"source":["#train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TzUxkN1fIg79","executionInfo":{"status":"ok","timestamp":1607111744241,"user_tz":-480,"elapsed":213081,"user":{"displayName":"葉彥廷","photoUrl":"","userId":"03165483084691048586"}},"outputId":"317e70b7-8c84-425c-da9c-455425eea59c"},"source":["from tensorboardX import SummaryWriter\n","\n","model_dir = \"./model1\"\n","use_gpu = False #not needed, cpu is enough here\n","log = True #require tensorboard\n","log_dir = './log'\n","\n","model = LogisticRegression()\n","opt = torch.optim.Adam(model.parameters(), lr = 1e-3)\n","#model, opt = load_model(model_dir, model, opt, -1)\n","if use_gpu:\n","  model = model.to('cuda')\n","if log:\n","  logger = SummaryWriter(log_dir)\n","model.train()\n","print(\"start training\")\n","s_t = time.time()\n","for iteration in range(0, 3000):\n","  x, y = next(train_iterator)\n","  #x, y = train_dataset.__getitem__(0)\n","  x = x.float()\n","  #print(torch.sum(x, 1) / x.size()[1])\n","  #print(x.size())\n","  #print(y.size())\n","  if use_gpu:\n","    x = x.to('cuda')\n","    y = y.to('cuda')\n","  y_pred = model(x)\n","  #print(y_pred.size())\n","  loss = get_loss(y, y_pred)\n","  opt.zero_grad()\n","  loss.backward()\n","  opt.step()\n","  if ((iteration+1) % 100 == 0):\n","    et = time.time() - s_t\n","    et = str(datetime.timedelta(seconds=et))[:-7]\n","    print(\"[{}]iteration {} loss: {}\".format(et, iteration+1, loss.item()))\n","    if log:\n","      logger.add_scalar('L1 loss', loss, iteration+1)\n","  if ((iteration+1) % 1000 == 0):\n","    save_model(model_dir, model, opt, -1)\n","  if ((iteration+1) % 1000 == 0):\n","    save_model(model_dir, model, opt, iteration+1)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["start training\n","[0:00:08]iteration 100 loss: 0.2631032794161001\n","[0:00:15]iteration 200 loss: 0.1610944625499542\n","[0:00:22]iteration 300 loss: 0.11242317681656762\n","[0:00:28]iteration 400 loss: 0.09508434998012187\n","[0:00:35]iteration 500 loss: 0.07859054910113628\n","[0:00:42]iteration 600 loss: 0.060412948532454415\n","[0:00:49]iteration 700 loss: 0.06284219680674141\n","[0:00:56]iteration 800 loss: 0.05895390882862254\n","[0:01:02]iteration 900 loss: 0.06398943880049046\n","[0:01:09]iteration 1000 loss: 0.057787239741855956\n","[0:01:19]iteration 1100 loss: 0.06239357281545684\n","[0:01:26]iteration 1200 loss: 0.06253886151527392\n","[0:01:33]iteration 1300 loss: 0.046585924793930644\n","[0:01:40]iteration 1400 loss: 0.05955934148467653\n","[0:01:47]iteration 1500 loss: 0.06110280457168452\n","[0:01:54]iteration 1600 loss: 0.05117822363013147\n","[0:02:01]iteration 1700 loss: 0.05139798370572635\n","[0:02:08]iteration 1800 loss: 0.0413441271754967\n","[0:02:15]iteration 1900 loss: 0.057608185894575094\n","[0:02:22]iteration 2000 loss: 0.0525592575330999\n","[0:02:28]iteration 2100 loss: 0.05308849003792678\n","[0:02:35]iteration 2200 loss: 0.05021264182368176\n","[0:02:42]iteration 2300 loss: 0.030308618758946675\n","[0:02:49]iteration 2400 loss: 0.052365162917283214\n","[0:02:56]iteration 2500 loss: 0.05652786065172677\n","[0:03:03]iteration 2600 loss: 0.04398612183465881\n","[0:03:10]iteration 2700 loss: 0.05284884339921329\n","[0:03:17]iteration 2800 loss: 0.04276920657380856\n","[0:03:24]iteration 2900 loss: 0.04925864528062599\n","[0:03:31]iteration 3000 loss: 0.05262384337446709\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jqaHCc7DHsTJ"},"source":["#load dev data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rjtcKHvCHNh_"},"source":["print(\"loading data...\")\n","s_t = time.time()\n","\n","dev_dataset = myDataset('./data/processed/dev.csv')\n","dev_loader = DataLoader(dev_dataset, batch_size=1, shuffle=False, num_workers=2)\n","dev_iterator = infinite_iter(dev_loader)\n","\n","print(\"data prepared!\")\n","et = time.time() - s_t\n","et = str(datetime.timedelta(seconds=et))[:-7]\n","print(\"[{}]\".format(et))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hRsG0EaMJhjO","executionInfo":{"status":"ok","timestamp":1607110333003,"user_tz":-480,"elapsed":492,"user":{"displayName":"葉彥廷","photoUrl":"","userId":"03165483084691048586"}}},"source":["def map7(pred, label): #pred, label: numpay 1d array\n","  ind = []\n","  for i in range(0, len(label)): #length should be 24\n","    if label[i] == 1:\n","      ind.append(i)\n","  L = len(ind)\n","  L = min(7, L)\n","  if L == 0:\n","    return 0\n","  \n","  pred = pred.argsort()[-7:][::-1]\n","  #print(ind)\n","  #print(pred)\n","\n","  score = 0\n","  precision = 0\n","  for i in range(0, 7):\n","    if (pred[i] in ind):\n","      precision += 1\n","      score += precision / (i+1)\n","  score  = score / L\n","  return score"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"pGRi2U3THVC8"},"source":["#validation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"htd2_CwXH42E"},"source":["model_dir = './model1'\n","#use_gpu = False\n","\n","model = LogisticRegression()\n","opt = torch.optim.Adam(model.parameters(), lr = 1e-3)\n","model, opt = load_model(model_dir, model, opt, 10000)\n","model.eval()\n","#if use_gpu:\n","  #model = model.to('cuda')\n","\n","score = 0\n","dev_sample = 10000\n","for i in range(0, dev_sample):\n","  x, y = next(dev_iterator)\n","  x = x.float()\n","  pred = model(x)\n","  #print(x.squeeze().size(), y.squeeze().size(), pred.squeeze().size())\n","  _score = map7(pred.detach().squeeze().numpy(), y.detach().squeeze().numpy())\n","  score += _score\n","  if (i+1) % 1000 == 0:\n","    print(\"progress: {}/{}\".format(i+1, dev_sample))\n","\n","print(\"MAP@7 score:\", score / dev_sample)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OmnihpgFO-pQ"},"source":["_c = 0\n","for iteration in range(0, 1):\n","  x, y = next(train_iterator)\n","  for i in range(0, 128):\n","    _y = y[i]\n","    s = torch.sum(_y)\n","    if s > 1:\n","      _c += 1\n","      print(_y)\n","print(_c)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5F1fIS4OqKVP"},"source":["del train_dataset.df_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aGoVuogwrEyu"},"source":["train_dataset.df_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cLlH8HEyst8r"},"source":["a = pd.read_csv(\"./data/processed/ver1_1.csv\")"],"execution_count":null,"outputs":[]}]}